{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Libraries, Dependencies and Parameters\n","metadata":{"papermill":{"duration":0.009676,"end_time":"2023-05-07T15:19:18.836812","exception":false,"start_time":"2023-05-07T15:19:18.827136","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"_Install Required Libraries_\n","metadata":{"papermill":{"duration":0.008697,"end_time":"2023-05-07T15:19:18.855069","exception":false,"start_time":"2023-05-07T15:19:18.846372","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%pip install openprompt\n%pip install evaluate\n%pip install adapter-transformers==3.1.0","metadata":{"id":"GJnzG561XzuD","outputId":"8a1c54ef-d5f9-4ac9-9b92-6dff736b9344","papermill":{"duration":20.826194,"end_time":"2023-05-07T15:19:39.690496","exception":false,"start_time":"2023-05-07T15:19:18.864302","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:40:12.642666Z","iopub.execute_input":"2023-05-15T03:40:12.643506Z","iopub.status.idle":"2023-05-15T03:40:55.577148Z","shell.execute_reply.started":"2023-05-15T03:40:12.643467Z","shell.execute_reply":"2023-05-15T03:40:55.575877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_Dependencies_\n","metadata":{"execution":{"iopub.execute_input":"2023-04-19T11:46:38.93501Z","iopub.status.busy":"2023-04-19T11:46:38.934658Z","iopub.status.idle":"2023-04-19T11:46:49.19186Z","shell.execute_reply":"2023-04-19T11:46:49.190506Z","shell.execute_reply.started":"2023-04-19T11:46:38.93497Z"},"papermill":{"duration":0.010331,"end_time":"2023-05-07T15:19:39.712081","exception":false,"start_time":"2023-05-07T15:19:39.70175","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nimport time\nimport evaluate\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\nfrom tqdm import tqdm\nfrom datasets import load_metric\nfrom openprompt import PromptDataLoader, PromptForClassification\nfrom openprompt.data_utils import InputExample\nfrom openprompt.prompts import MixedTemplate, SoftVerbalizer\nfrom openprompt.plms.utils import TokenizerWrapper\nfrom transformers import AdamW, get_linear_schedule_with_warmup, XLMRobertaConfig, XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaForMaskedLM, set_seed, AdapterConfig\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE\nfrom prettytable import PrettyTable","metadata":{"id":"6BIRiGiWkVU6","papermill":{"duration":12.896657,"end_time":"2023-05-07T15:19:52.619068","exception":false,"start_time":"2023-05-07T15:19:39.722411","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:40:55.579663Z","iopub.execute_input":"2023-05-15T03:40:55.580044Z","iopub.status.idle":"2023-05-15T03:41:09.685092Z","shell.execute_reply.started":"2023-05-15T03:40:55.580004Z","shell.execute_reply":"2023-05-15T03:41:09.684164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings('ignore')","metadata":{"papermill":{"duration":0.018469,"end_time":"2023-05-07T15:19:52.649029","exception":false,"start_time":"2023-05-07T15:19:52.63056","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:09.686341Z","iopub.execute_input":"2023-05-15T03:41:09.686669Z","iopub.status.idle":"2023-05-15T03:41:09.694973Z","shell.execute_reply.started":"2023-05-15T03:41:09.686639Z","shell.execute_reply":"2023-05-15T03:41:09.692062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_Parameters_\n","metadata":{"papermill":{"duration":0.010363,"end_time":"2023-05-07T15:19:52.669881","exception":false,"start_time":"2023-05-07T15:19:52.659518","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_type = \"XLM-R\"\ntechnique = \"Sentiment\" #@param [\"Sentiment\", \"Humor\", \"Hate-Speech\"]\nuse_cuda = True\nno_of_labels = 4 #Sentiment:4, Humor:2, Hate-Speech:3\nvalidation_size = (1/9)\ntest_size = 0.1\nsplit_random_state = 42\nmax_seq_length = 128\nbatch_size = 32\nnum_train_epochs = 20\ntraining_seed = 8 #@param [8, 42, 77]\nscript = \"Char-Script-1.0\"","metadata":{"id":"JUCDlx1akOCt","papermill":{"duration":0.022989,"end_time":"2023-05-07T15:19:52.703493","exception":false,"start_time":"2023-05-07T15:19:52.680504","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:09.698138Z","iopub.execute_input":"2023-05-15T03:41:09.69906Z","iopub.status.idle":"2023-05-15T03:41:09.711345Z","shell.execute_reply.started":"2023-05-15T03:41:09.699026Z","shell.execute_reply":"2023-05-15T03:41:09.710151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Preprocessing\n","metadata":{"papermill":{"duration":0.010294,"end_time":"2023-05-07T15:19:52.724675","exception":false,"start_time":"2023-05-07T15:19:52.714381","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/sinhala-english-cmcs-dataset/annotated-script(all).csv\")\ndf = df[['Sentence', technique, script]]\ndf.columns = ['Sentence', 'Label', script]","metadata":{"papermill":{"duration":0.105055,"end_time":"2023-05-07T15:19:52.840158","exception":false,"start_time":"2023-05-07T15:19:52.735103","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:09.712659Z","iopub.execute_input":"2023-05-15T03:41:09.713107Z","iopub.status.idle":"2023-05-15T03:41:09.808607Z","shell.execute_reply.started":"2023-05-15T03:41:09.713073Z","shell.execute_reply":"2023-05-15T03:41:09.807679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Label Encoding*","metadata":{"papermill":{"duration":0.010524,"end_time":"2023-05-07T15:19:52.861823","exception":false,"start_time":"2023-05-07T15:19:52.851299","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df['Label'], uniq = pd.factorize(df['Label'])","metadata":{"papermill":{"duration":0.021606,"end_time":"2023-05-07T15:19:52.894105","exception":false,"start_time":"2023-05-07T15:19:52.872499","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:09.810081Z","iopub.execute_input":"2023-05-15T03:41:09.81042Z","iopub.status.idle":"2023-05-15T03:41:09.818459Z","shell.execute_reply.started":"2023-05-15T03:41:09.810387Z","shell.execute_reply":"2023-05-15T03:41:09.817511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Train, Validation & Test Split*","metadata":{"papermill":{"duration":0.010374,"end_time":"2023-05-07T15:19:52.915077","exception":false,"start_time":"2023-05-07T15:19:52.904703","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X, y = df[['Sentence', script]], df[['Label']]\nstratifying_col = y[\"Label\"]\nX_rem, X_test, y_rem, y_test = train_test_split(X, y, test_size=test_size, stratify=stratifying_col, random_state=split_random_state)\nstratifying_col = y_rem[\"Label\"]\nX_train, X_validation, y_train, y_validation = train_test_split(X_rem, y_rem, test_size=validation_size, stratify=stratifying_col, random_state=split_random_state)","metadata":{"papermill":{"duration":0.034364,"end_time":"2023-05-07T15:19:52.96059","exception":false,"start_time":"2023-05-07T15:19:52.926226","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:09.819912Z","iopub.execute_input":"2023-05-15T03:41:09.820589Z","iopub.status.idle":"2023-05-15T03:41:09.850641Z","shell.execute_reply.started":"2023-05-15T03:41:09.820551Z","shell.execute_reply":"2023-05-15T03:41:09.849831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train : Rows =\", X_train.shape[0], \", Columns = \", X_train.shape[1])\nprint(\"y_train : Rows =\", y_train.shape[0], \", Columns = \", y_train.shape[1])\nprint(\"X_validation : Rows =\", X_validation.shape[0], \", Columns = \", X_validation.shape[1])\nprint(\"y_validation : Rows =\", y_validation.shape[0], \", Columns = \", y_validation.shape[1])\nprint(\"X_test : Rows =\", X_test.shape[0], \", Columns = \", X_test.shape[1])\nprint(\"y_test : Rows =\", y_test.shape[0], \", Columns = \", y_test.shape[1])","metadata":{"papermill":{"duration":0.019437,"end_time":"2023-05-07T15:19:53.020284","exception":false,"start_time":"2023-05-07T15:19:53.000847","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:09.852014Z","iopub.execute_input":"2023-05-15T03:41:09.852345Z","iopub.status.idle":"2023-05-15T03:41:09.859424Z","shell.execute_reply.started":"2023-05-15T03:41:09.852315Z","shell.execute_reply":"2023-05-15T03:41:09.858431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Labels :\", ['Negative', 'Neutral', 'Positive', 'Conflict'])\nprint(\"Train :\", y_train.groupby('Label').size().tolist())\nprint(\"Validation :\", y_validation.groupby('Label').size().tolist())\nprint(\"Test :\", y_test.groupby('Label').size().tolist())","metadata":{"papermill":{"duration":0.023369,"end_time":"2023-05-07T15:19:53.05439","exception":false,"start_time":"2023-05-07T15:19:53.031021","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:09.861121Z","iopub.execute_input":"2023-05-15T03:41:09.86156Z","iopub.status.idle":"2023-05-15T03:41:09.876319Z","shell.execute_reply.started":"2023-05-15T03:41:09.861529Z","shell.execute_reply":"2023-05-15T03:41:09.874878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## OpenPrompt\n","metadata":{"papermill":{"duration":0.010768,"end_time":"2023-05-07T15:19:53.160478","exception":false,"start_time":"2023-05-07T15:19:53.14971","status":"completed"},"tags":[]}},{"cell_type":"code","source":"set_seed(training_seed)\ntorch.backends.cudnn.deterministic = True ","metadata":{"papermill":{"duration":0.023119,"end_time":"2023-05-07T15:19:53.194647","exception":false,"start_time":"2023-05-07T15:19:53.171528","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:09.909432Z","iopub.execute_input":"2023-05-15T03:41:09.909755Z","iopub.status.idle":"2023-05-15T03:41:09.922868Z","shell.execute_reply.started":"2023-05-15T03:41:09.909725Z","shell.execute_reply":"2023-05-15T03:41:09.922011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MLMTokenizerWrapper(TokenizerWrapper):\n    add_input_keys = ['input_ids', 'attention_mask', 'token_type_ids']\n\n    @property\n    def mask_token(self):\n        return self.tokenizer.mask_token\n\n    @property\n    def mask_token_ids(self):\n        return self.tokenizer.mask_token_id\n\n    @property\n    def num_special_tokens_to_add(self):\n        if not hasattr(self, '_num_specials'):\n            self._num_specials = self.tokenizer.num_special_tokens_to_add()\n        return self._num_specials\n\n    def tokenize_one_example(self, wrapped_example, teacher_forcing):\n        wrapped_example, others = wrapped_example\n        encoded_tgt_text = []\n        if 'tgt_text' in others:\n            tgt_text = others['tgt_text']\n            if isinstance(tgt_text, str):\n                tgt_text = [tgt_text]\n            for t in tgt_text:\n                encoded_tgt_text.append(self.tokenizer.encode(t, add_special_tokens=False))\n\n        mask_id = 0 # the i-th the mask token in the template.\n\n        encoder_inputs = defaultdict(list)\n        for piece in wrapped_example:\n            if piece['loss_ids']==1:\n                if teacher_forcing: # fill the mask with the tgt task\n                    raise RuntimeError(\"Masked Language Model can't perform teacher forcing training!\")\n                else:\n                    encode_text = [self.mask_token_ids]\n                mask_id += 1\n\n            if piece['text'] in self.special_tokens_maps.keys():\n                to_replace = self.special_tokens_maps[piece['text']]\n                if to_replace is not None:\n                    piece['text'] = to_replace\n                else:\n                    raise KeyError(\"This tokenizer doesn't specify {} token.\".format(piece['text']))\n\n            if 'soft_token_ids' in piece and piece['soft_token_ids']!=0:\n                encode_text = [0] # can be replace by any token, since these token will use their own embeddings\n            else:\n                encode_text = self.tokenizer.encode(piece['text'], add_special_tokens=False)\n\n            encoding_length = len(encode_text)\n            encoder_inputs['input_ids'].append(encode_text)\n            for key in piece:\n                if key not in ['text']:\n                    encoder_inputs[key].append([piece[key]]*encoding_length)\n\n        encoder_inputs = self.truncate(encoder_inputs=encoder_inputs)\n        # delete shortenable ids\n        encoder_inputs.pop(\"shortenable_ids\")\n        encoder_inputs = self.concate_parts(input_dict=encoder_inputs)\n        encoder_inputs = self.add_special_tokens(encoder_inputs=encoder_inputs)\n        # create special input ids\n        encoder_inputs['attention_mask'] = [1] *len(encoder_inputs['input_ids'])\n        if self.create_token_type_ids:\n            encoder_inputs['token_type_ids'] = [0] *len(encoder_inputs['input_ids'])\n        # padding\n        encoder_inputs = self.padding(input_dict=encoder_inputs, max_len=self.max_seq_length, pad_id_for_inputs=self.tokenizer.pad_token_id)\n\n        if len(encoded_tgt_text) > 0:\n            encoder_inputs = {**encoder_inputs, \"encoded_tgt_text\": encoded_tgt_text}# convert defaultdict to dict\n        else:\n            encoder_inputs = {**encoder_inputs}\n        return encoder_inputs","metadata":{"id":"bq3XoGPBdJri","papermill":{"duration":0.025151,"end_time":"2023-05-07T15:19:53.23089","exception":false,"start_time":"2023-05-07T15:19:53.205739","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:09.924337Z","iopub.execute_input":"2023-05-15T03:41:09.924708Z","iopub.status.idle":"2023-05-15T03:41:09.940885Z","shell.execute_reply.started":"2023-05-15T03:41:09.924677Z","shell.execute_reply":"2023-05-15T03:41:09.939549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_plm(model_name, model_path):   \n    model_config = XLMRobertaConfig.from_pretrained(model_path)\n    model = XLMRobertaForMaskedLM.from_pretrained(model_path, config=model_config)\n    tokenizer = XLMRobertaTokenizer.from_pretrained(model_path)\n    wrapper = MLMTokenizerWrapper\n    return model, tokenizer, wrapper","metadata":{"id":"71QIB8CjdRPI","papermill":{"duration":0.029059,"end_time":"2023-05-07T15:19:53.27096","exception":false,"start_time":"2023-05-07T15:19:53.241901","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:09.94247Z","iopub.execute_input":"2023-05-15T03:41:09.943735Z","iopub.status.idle":"2023-05-15T03:41:09.954209Z","shell.execute_reply.started":"2023-05-15T03:41:09.943708Z","shell.execute_reply":"2023-05-15T03:41:09.953308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_Load Pre-trained Language Model (PLM)_\n","metadata":{"papermill":{"duration":0.011006,"end_time":"2023-05-07T15:19:53.292875","exception":false,"start_time":"2023-05-07T15:19:53.281869","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plm, tokenizer, wrapper_class = load_plm(\"xlm\", \"xlm-roberta-base\")","metadata":{"id":"NDPRMGSXdUwW","outputId":"c322f46e-4506-45f8-84b4-cc3804d9c171","papermill":{"duration":52.158195,"end_time":"2023-05-07T15:20:45.462343","exception":false,"start_time":"2023-05-07T15:19:53.304148","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:09.955443Z","iopub.execute_input":"2023-05-15T03:41:09.956033Z","iopub.status.idle":"2023-05-15T03:41:39.039079Z","shell.execute_reply.started":"2023-05-15T03:41:09.955957Z","shell.execute_reply":"2023-05-15T03:41:39.038077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Adapter Configuration**","metadata":{}},{"cell_type":"code","source":"adapter_name = \"All_Sentiment\"\nadapter_config = AdapterConfig.load(\"houlsby\") #@param = [\"pfeiffer\", \"houlsby\"]\n# adapter_config.leave_out.extend([9, 10, 11])\nplm.add_adapter(adapter_name, config=adapter_config)\nplm.set_active_adapters(adapter_name)\nplm.train_adapter(adapter_name)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:41:39.040751Z","iopub.execute_input":"2023-05-15T03:41:39.041131Z","iopub.status.idle":"2023-05-15T03:41:39.134343Z","shell.execute_reply.started":"2023-05-15T03:41:39.041097Z","shell.execute_reply":"2023-05-15T03:41:39.13348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Prompt Template, Verbalizer and PLM**\n","metadata":{"papermill":{"duration":0.011262,"end_time":"2023-05-07T15:20:45.485648","exception":false,"start_time":"2023-05-07T15:20:45.474386","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"*Prompt Model for Latin Script*","metadata":{}},{"cell_type":"code","source":"template_latin = '{\"placeholder\": \"text_a\"}. {\"soft\": \"The\"} {\"soft\": \"sentiment\"} {\"soft\": \"or\"} {\"soft\": \"the\"} {\"soft\": \"feeling\"} {\"soft\": \"of\"} {\"soft\": \"the\"} {\"soft\": \"given\"} {\"soft\": \"sentence\"} {\"soft\": \"can\"} {\"soft\": \"be\"} {\"soft\": \"classified\"} {\"soft\": \"as\"} {\"soft\": \"positive\"} {\"soft\": \",\"} {\"soft\": \"negative\"} {\"soft\": \"or\"} {\"soft\": \"neutral\"} {\"soft\": \".\"} {\"soft\": \"The\"} {\"soft\": \"classified\"} {\"soft\": \"sentiment\"} {\"soft\": \"of\"} {\"soft\": \"the\"} {\"soft\": \"sentence\"} {\"soft\": \"is\"} {\"mask\"}.'\npromptTemplate_latin = MixedTemplate(model=plm, text = template_latin, tokenizer = tokenizer)\npromptVerbalizer_latin = SoftVerbalizer(tokenizer, plm, num_classes=no_of_labels)\npromptModel_latin = PromptForClassification(template = promptTemplate_latin, plm = plm, verbalizer = promptVerbalizer_latin)","metadata":{"id":"jD4_Q5w0dXqx","papermill":{"duration":0.501199,"end_time":"2023-05-07T15:20:45.99818","exception":false,"start_time":"2023-05-07T15:20:45.496981","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:39.135865Z","iopub.execute_input":"2023-05-15T03:41:39.136229Z","iopub.status.idle":"2023-05-15T03:41:39.621692Z","shell.execute_reply.started":"2023-05-15T03:41:39.136196Z","shell.execute_reply":"2023-05-15T03:41:39.620736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Prompt Model for Sinhala Script*","metadata":{}},{"cell_type":"code","source":"template_sinhala = '{\"placeholder\": \"text_a\"}. {\"soft\": \"මෙය\"} {\"mask\"} {\"soft\": \"ප්‍රකාශයකි\"}.'\npromptTemplate_sinhala = MixedTemplate(model=plm, text = template_sinhala, tokenizer = tokenizer)\npromptVerbalizer_sinhala = SoftVerbalizer(tokenizer, plm, num_classes=no_of_labels)\npromptModel_sinhala = PromptForClassification(template = promptTemplate_sinhala, plm = plm, verbalizer = promptVerbalizer_sinhala)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:41:39.62331Z","iopub.execute_input":"2023-05-15T03:41:39.623693Z","iopub.status.idle":"2023-05-15T03:41:40.102861Z","shell.execute_reply.started":"2023-05-15T03:41:39.623648Z","shell.execute_reply":"2023-05-15T03:41:40.101929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Prompt Model for Mixed Script*","metadata":{}},{"cell_type":"code","source":"template_mixed = '{\"placeholder\": \"text_a\"}. {\"soft\": \"The\"} {\"soft\": \"sentiment\"} {\"soft\": \"or\"} {\"soft\": \"the\"} {\"soft\": \"feeling\"} {\"soft\": \"of\"} {\"soft\": \"the\"} {\"soft\": \"given\"} {\"soft\": \"sentence\"} {\"soft\": \"can\"} {\"soft\": \"be\"} {\"soft\": \"classified\"} {\"soft\": \"as\"} {\"soft\": \"positive\"} {\"soft\": \",\"} {\"soft\": \"negative\"} {\"soft\": \"or\"} {\"soft\": \"neutral\"} {\"soft\": \".\"} {\"soft\": \"The\"} {\"soft\": \"classified\"} {\"soft\": \"sentiment\"} {\"soft\": \"of\"} {\"soft\": \"the\"} {\"soft\": \"sentence\"} {\"soft\": \"is\"} {\"mask\"}.'\npromptTemplate_mixed = MixedTemplate(model=plm, text = template_mixed, tokenizer = tokenizer)\npromptVerbalizer_mixed = SoftVerbalizer(tokenizer, plm, num_classes=no_of_labels)\npromptModel_mixed = PromptForClassification(template = promptTemplate_mixed, plm = plm, verbalizer = promptVerbalizer_mixed)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:41:40.10428Z","iopub.execute_input":"2023-05-15T03:41:40.104625Z","iopub.status.idle":"2023-05-15T03:41:40.587483Z","shell.execute_reply.started":"2023-05-15T03:41:40.104593Z","shell.execute_reply":"2023-05-15T03:41:40.586418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create DataLoaders\n","metadata":{"papermill":{"duration":0.011294,"end_time":"2023-05-07T15:20:46.052522","exception":false,"start_time":"2023-05-07T15:20:46.041228","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_train, y_train = X_train.values.tolist(), y_train.values.tolist()\nX_validation, y_validation = X_validation.values.tolist(), y_validation.values.tolist()\nX_test, y_test = X_test.values.tolist(), y_test.values.tolist()","metadata":{"papermill":{"duration":0.026123,"end_time":"2023-05-07T15:20:46.090225","exception":false,"start_time":"2023-05-07T15:20:46.064102","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:40.589117Z","iopub.execute_input":"2023-05-15T03:41:40.589466Z","iopub.status.idle":"2023-05-15T03:41:40.604227Z","shell.execute_reply.started":"2023-05-15T03:41:40.589434Z","shell.execute_reply":"2023-05-15T03:41:40.603346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_Train Dataloader_\n","metadata":{"papermill":{"duration":0.011394,"end_time":"2023-05-07T15:20:46.113329","exception":false,"start_time":"2023-05-07T15:20:46.101935","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_examples_latin=[]\ntrain_examples_sinhala=[]\ntrain_examples_mixed=[]\n\nfor i in range(len(X_train)):\n    if(X_train[i][1]==\"Latin\"):\n        train_examples_latin.append(InputExample(guid = i, text_a = X_train[i][0], label = y_train[i][0]))\n    elif(X_train[i][1]==\"Sinhala\"):\n        train_examples_sinhala.append(InputExample(guid = i, text_a = X_train[i][0], label = y_train[i][0]))    \n    elif(X_train[i][1]==\"Mixed\"):\n        train_examples_mixed.append(InputExample(guid = i, text_a = X_train[i][0], label = y_train[i][0]))\n\ntrain_data_loader_latin = PromptDataLoader(\n    dataset = train_examples_latin,\n    tokenizer = tokenizer,\n    template = promptTemplate_latin,\n    tokenizer_wrapper_class=wrapper_class,\n    batch_size=batch_size,\n    max_seq_length=max_seq_length,\n    truncation=True,\n    padding=\"max_length\"\n).dataloader\ntrain_data_loader_sinhala = PromptDataLoader(\n    dataset = train_examples_sinhala,\n    tokenizer = tokenizer,\n    template = promptTemplate_sinhala,\n    tokenizer_wrapper_class=wrapper_class,\n    batch_size=batch_size,\n    max_seq_length=max_seq_length,\n    truncation=True,\n    padding=\"max_length\"\n).dataloader\ntrain_data_loader_mixed = PromptDataLoader(\n    dataset = train_examples_mixed,\n    tokenizer = tokenizer,\n    template = promptTemplate_mixed,\n    tokenizer_wrapper_class=wrapper_class,\n    batch_size=batch_size,\n    max_seq_length=max_seq_length,\n    truncation=True,\n    padding=\"max_length\",\n).dataloader","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:41:40.605815Z","iopub.execute_input":"2023-05-15T03:41:40.606144Z","iopub.status.idle":"2023-05-15T03:41:52.393097Z","shell.execute_reply.started":"2023-05-15T03:41:40.606113Z","shell.execute_reply":"2023-05-15T03:41:52.392046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_Validation Dataloader_\n","metadata":{"papermill":{"duration":0.015936,"end_time":"2023-05-07T15:20:56.220396","exception":false,"start_time":"2023-05-07T15:20:56.20446","status":"completed"},"tags":[]}},{"cell_type":"code","source":"validation_examples_latin=[]\nvalidation_examples_sinhala=[]\nvalidation_examples_mixed=[]\n\nfor i in range(len(X_validation)):\n    if(X_validation[i][1]==\"Latin\"):\n        validation_examples_latin.append(InputExample(guid = i, text_a = X_validation[i][0], label = y_validation[i][0]))\n    elif(X_validation[i][1]==\"Sinhala\"):\n        validation_examples_sinhala.append(InputExample(guid = i, text_a = X_validation[i][0], label = y_validation[i][0]))    \n    elif(X_validation[i][1]==\"Mixed\"):\n        validation_examples_mixed.append(InputExample(guid = i, text_a = X_validation[i][0], label = y_validation[i][0]))\n\nvalidation_data_loader_latin = PromptDataLoader(\n    dataset = validation_examples_latin,\n    tokenizer = tokenizer,\n    template = promptTemplate_latin,\n    tokenizer_wrapper_class=wrapper_class,\n    batch_size=batch_size,\n    max_seq_length=max_seq_length,\n    truncation=True,\n    padding=\"max_length\"\n).dataloader\nvalidation_data_loader_sinhala = PromptDataLoader(\n    dataset = validation_examples_sinhala,\n    tokenizer = tokenizer,\n    template = promptTemplate_sinhala,\n    tokenizer_wrapper_class=wrapper_class,\n    batch_size=batch_size,\n    max_seq_length=max_seq_length,\n    truncation=True,\n    padding=\"max_length\"\n).dataloader\nvalidation_data_loader_mixed = PromptDataLoader(\n    dataset = validation_examples_mixed,\n    tokenizer = tokenizer,\n    template = promptTemplate_mixed,\n    tokenizer_wrapper_class=wrapper_class,\n    batch_size=batch_size,\n    max_seq_length=max_seq_length,\n    truncation=True,\n    padding=\"max_length\",\n).dataloader","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:41:52.394837Z","iopub.execute_input":"2023-05-15T03:41:52.395512Z","iopub.status.idle":"2023-05-15T03:41:53.934729Z","shell.execute_reply.started":"2023-05-15T03:41:52.395476Z","shell.execute_reply":"2023-05-15T03:41:53.933714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_Test Dataloader_\n","metadata":{"papermill":{"duration":0.017104,"end_time":"2023-05-07T15:20:57.517585","exception":false,"start_time":"2023-05-07T15:20:57.500481","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_examples_latin=[]\ntest_examples_sinhala=[]\ntest_examples_mixed=[]\n\nfor i in range(len(X_test)):\n    if(X_test[i][1]==\"Latin\"):\n        test_examples_latin.append(InputExample(guid = i, text_a = X_test[i][0], label = y_test[i][0]))\n    elif(X_test[i][1]==\"Sinhala\"):\n        test_examples_sinhala.append(InputExample(guid = i, text_a = X_test[i][0], label = y_test[i][0]))    \n    elif(X_test[i][1]==\"Mixed\"):\n        test_examples_mixed.append(InputExample(guid = i, text_a = X_test[i][0], label = y_test[i][0]))\n\ntest_data_loader_latin = PromptDataLoader(\n    dataset = test_examples_latin,\n    tokenizer = tokenizer,\n    template = promptTemplate_latin,\n    tokenizer_wrapper_class=wrapper_class,\n    batch_size=batch_size,\n    max_seq_length=max_seq_length,\n    truncation=True,\n    padding=\"max_length\"\n).dataloader\ntest_data_loader_sinhala = PromptDataLoader(\n    dataset = test_examples_sinhala,\n    tokenizer = tokenizer,\n    template = promptTemplate_sinhala,\n    tokenizer_wrapper_class=wrapper_class,\n    batch_size=batch_size,\n    max_seq_length=max_seq_length,\n    truncation=True,\n    padding=\"max_length\"\n).dataloader\ntest_data_loader_mixed = PromptDataLoader(\n    dataset = test_examples_mixed,\n    tokenizer = tokenizer,\n    template = promptTemplate_mixed,\n    tokenizer_wrapper_class=wrapper_class,\n    batch_size=batch_size,\n    max_seq_length=max_seq_length,\n    truncation=True,\n    padding=\"max_length\",\n).dataloader","metadata":{"papermill":{"duration":2.382593,"end_time":"2023-05-07T15:20:59.922252","exception":false,"start_time":"2023-05-07T15:20:57.539659","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:53.936287Z","iopub.execute_input":"2023-05-15T03:41:53.936885Z","iopub.status.idle":"2023-05-15T03:41:55.849112Z","shell.execute_reply.started":"2023-05-15T03:41:53.936849Z","shell.execute_reply":"2023-05-15T03:41:55.847777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Optimizer and Scheduler","metadata":{}},{"cell_type":"code","source":"no_decay = ['bias', 'LayerNorm.weight']\nbetas = (0.9, 0.999)\neps = 1e-08\nnum_training_steps = len(X_train) * num_train_epochs # After the num_training_steps lr will be 0 \n\n# ==== Latin ====\nlatin_num_warmup_steps = 250\nlatin_sp_lr = 1e-3\nlatin_sv_gp_1_lr = 4e-5\nlatin_sv_gp_2_lr = 4e-4\n\n# ==== Sinhala ====\nsinhala_num_warmup_steps = 1500\nsinhala_sp_lr = 1e-2\nsinhala_sv_gp_1_lr = 2e-2\nsinhala_sv_gp_2_lr = 2e-2\n\n# ==== Mixed ====\nmixed_num_warmup_steps = 1250\nmixed_sp_lr = 1e-2\nmixed_sv_gp_1_lr = 2e-2\nmixed_sv_gp_2_lr = 2e-2\n\n# ==== Shared Adapter ====\nadapter_wd_1 = 1e-2\nadapter_wd_2 = 0\nadapter_num_warmup_steps = 500\nadapter_lr = 5e-4","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:41:55.850752Z","iopub.execute_input":"2023-05-15T03:41:55.851713Z","iopub.status.idle":"2023-05-15T03:41:55.860049Z","shell.execute_reply.started":"2023-05-15T03:41:55.851672Z","shell.execute_reply":"2023-05-15T03:41:55.85886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_optimizer_and_scheduler(promptModel, sp_lr, sv_gp_1_lr, sv_gp_2_lr, num_warmup_steps, num_training_steps):   \n    sp_optimizer_grouped_parameters = [{'params': [p for n,p in promptModel.template.named_parameters() if \"raw_embedding\" not in n]}]\n    sp_optimizer = AdamW(sp_optimizer_grouped_parameters, lr=sp_lr, betas=betas, eps=eps)\n    sp_scheduler = get_linear_schedule_with_warmup(sp_optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps) # After the num_training_steps lr will be 0\n\n    sv_optimizer_grouped_parameters = [{'params': promptModel.verbalizer.group_parameters_1, \"lr\":sv_gp_1_lr}, {'params': promptModel.verbalizer.group_parameters_2, \"lr\":sv_gp_2_lr}]\n    sv_optimizer = AdamW(sv_optimizer_grouped_parameters,betas=betas,eps=eps)\n    sv_scheduler = get_linear_schedule_with_warmup(sv_optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n    \n    adapter_optimizer_grouped_parameters = [{'params': [p for n, p in promptModel.plm.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': adapter_wd_1}, {'params': [p for n, p in promptModel.plm.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': adapter_wd_2}]\n    adapter_optimizer = AdamW(adapter_optimizer_grouped_parameters, lr=adapter_lr, betas=betas, eps=eps)\n    adapter_scheduler = get_linear_schedule_with_warmup(adapter_optimizer, num_warmup_steps=adapter_num_warmup_steps, num_training_steps=num_training_steps)\n    \n    return sp_optimizer, sp_scheduler, sv_optimizer, sv_scheduler, adapter_optimizer, adapter_scheduler","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:41:55.863293Z","iopub.execute_input":"2023-05-15T03:41:55.863616Z","iopub.status.idle":"2023-05-15T03:41:55.877302Z","shell.execute_reply.started":"2023-05-15T03:41:55.863588Z","shell.execute_reply":"2023-05-15T03:41:55.875939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Evaluation Methods\n","metadata":{"papermill":{"duration":0.017882,"end_time":"2023-05-07T15:21:00.137321","exception":false,"start_time":"2023-05-07T15:21:00.119439","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def predict(promptModel, dataloader):\n    if use_cuda:\n        promptModel=promptModel.cuda()\n        \n    promptModel.eval()\n    allpreds = []\n    alllabels = []\n\n    for step, inputs in enumerate(dataloader):\n        if use_cuda:\n            inputs = inputs.cuda()\n        logits = promptModel(inputs)\n        labels = inputs['label']\n        alllabels.extend(labels.cpu().tolist())\n        allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n    return allpreds,alllabels","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:41:55.878987Z","iopub.execute_input":"2023-05-15T03:41:55.879514Z","iopub.status.idle":"2023-05-15T03:41:55.892098Z","shell.execute_reply.started":"2023-05-15T03:41:55.879479Z","shell.execute_reply":"2023-05-15T03:41:55.890974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(allpreds,alllabels):\n    metric1 = load_metric(\"precision\")\n    metric2 = load_metric(\"recall\")\n    metric3 = load_metric(\"f1\")\n    metric4 = load_metric(\"accuracy\")\n    \n    predictions, labels = allpreds,alllabels\n    precision = metric1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"]\n    recall = metric2.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"]\n    f1 = metric3.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n    accuracy = metric4.compute(predictions=predictions, references=labels)[\"accuracy\"]\n    macro_precision = metric1.compute(predictions=predictions, references=labels, average=\"macro\")[\"precision\"]\n    macro_recall = metric2.compute(predictions=predictions, references=labels, average=\"macro\")[\"recall\"]\n    macro_f1 = metric3.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n    return {\"accuracy\":accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"macro_precision\": macro_precision, \"macro_recall\": macro_recall, \"macro_f1\": macro_f1}","metadata":{"papermill":{"duration":0.027751,"end_time":"2023-05-07T15:21:00.183217","exception":false,"start_time":"2023-05-07T15:21:00.155466","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:55.893585Z","iopub.execute_input":"2023-05-15T03:41:55.894033Z","iopub.status.idle":"2023-05-15T03:41:55.906502Z","shell.execute_reply.started":"2023-05-15T03:41:55.893999Z","shell.execute_reply":"2023-05-15T03:41:55.905522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(promptModel, dataloader):\n    allpreds,alllabels=predict(promptModel, dataloader)\n    return compute_metrics(allpreds,alllabels)","metadata":{"papermill":{"duration":0.026123,"end_time":"2023-05-07T15:21:00.227704","exception":false,"start_time":"2023-05-07T15:21:00.201581","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:55.913194Z","iopub.execute_input":"2023-05-15T03:41:55.913585Z","iopub.status.idle":"2023-05-15T03:41:55.919018Z","shell.execute_reply.started":"2023-05-15T03:41:55.91356Z","shell.execute_reply":"2023-05-15T03:41:55.917969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_loss_and_f1(promptModel, dataloader):\n    if use_cuda:\n        promptModel=promptModel.cuda()\n    \n    promptModel.eval()\n    allpreds = []\n    alllabels = []\n    total_loss = 0\n\n    for step, inputs in enumerate(dataloader):\n        if use_cuda:\n            inputs = inputs.cuda()\n        logits = promptModel(inputs)\n        labels = inputs['label']\n        loss = (torch.nn.CrossEntropyLoss())(logits, labels)\n        total_loss += loss.item()\n        allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n        alllabels.extend(labels.cpu().tolist())\n    \n    macro_f1 = load_metric(\"f1\").compute(predictions=allpreds, references=alllabels, average=\"macro\")[\"f1\"]\n    return macro_f1, (total_loss/len(dataloader))","metadata":{"papermill":{"duration":0.034129,"end_time":"2023-05-07T15:21:00.280259","exception":false,"start_time":"2023-05-07T15:21:00.24613","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:55.9206Z","iopub.execute_input":"2023-05-15T03:41:55.92118Z","iopub.status.idle":"2023-05-15T03:41:55.930598Z","shell.execute_reply.started":"2023-05-15T03:41:55.921137Z","shell.execute_reply":"2023-05-15T03:41:55.929604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train\n","metadata":{"papermill":{"duration":0.037295,"end_time":"2023-05-07T15:21:00.354065","exception":false,"start_time":"2023-05-07T15:21:00.31677","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"_Training Parameters_","metadata":{}},{"cell_type":"code","source":"loss_func = torch.nn.CrossEntropyLoss()\npbar_update_freq = 10\n\nmax_grad_norm = 1.0\ngradient_accumulation_steps = 1\n\nval_metric = \"macro_f1\"\nearly_stop_epoch_thresh = num_train_epochs","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:41:55.932387Z","iopub.execute_input":"2023-05-15T03:41:55.932724Z","iopub.status.idle":"2023-05-15T03:41:55.944755Z","shell.execute_reply.started":"2023-05-15T03:41:55.932692Z","shell.execute_reply":"2023-05-15T03:41:55.943848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(script, promptModel, sp_lr, sv_gp_1_lr, sv_gp_2_lr, num_warmup_steps, train_data_loader, validation_data_loader):\n    if use_cuda:\n        promptModel=promptModel.cuda()\n    set_seed(training_seed)\n    \n    # Train Parameters    \n    tot_loss = 0\n    log_loss = 0\n    best_val_acc = 0\n\n    glb_step = 0\n    actual_step = 0\n    leave_training = False\n    best_epoch = -1\n    \n    epoch_traces = []\n    acc_traces = []\n    validation_loss_traces = []\n    \n    num_training_steps = len(train_data_loader) * num_train_epochs # After the num_training_steps lr will be 0 \n    \n    # Optimizer and Scheduler\n    sp_optimizer, sp_scheduler, sv_optimizer, sv_scheduler, adapter_optimizer, adapter_scheduler = create_optimizer_and_scheduler(promptModel, sp_lr, sv_gp_1_lr, sv_gp_2_lr, num_warmup_steps, num_training_steps)\n    \n    # Train\n    pbar = tqdm(total=num_training_steps, desc=\"Train\")\n    for epoch in range(num_train_epochs):\n        print(f\"Begin Epoch {epoch}\")\n        epoch_start_time = time.time()\n        for step, inputs in enumerate(train_data_loader):\n            if use_cuda:\n                inputs = inputs.cuda()\n            logits = promptModel(inputs)\n            labels = inputs['label']\n            loss = loss_func(logits, labels)\n            loss = loss / gradient_accumulation_steps\n            loss.backward()\n            tot_loss += loss.item()\n            actual_step += 1\n\n            if actual_step % gradient_accumulation_steps == 0:\n                torch.nn.utils.clip_grad_norm_(promptModel.parameters(), max_grad_norm)\n                glb_step += 1\n\n                if glb_step % pbar_update_freq == 0:              \n                    aveloss = (tot_loss - log_loss)/pbar_update_freq\n                    pbar.update(pbar_update_freq)\n                    pbar.set_postfix({'Average Loss': aveloss, \"Epoch\": epoch})\n                    log_loss = tot_loss\n\n                if sp_optimizer is not None:\n                    sp_optimizer.step()\n                    sp_optimizer.zero_grad()\n                if sp_scheduler is not None:\n                    sp_scheduler.step()\n                if sv_optimizer is not None:\n                    sv_optimizer.step()\n                    sv_optimizer.zero_grad()\n                if sv_scheduler is not None:\n                    sv_scheduler.step()\n                if adapter_optimizer is not None:\n                    adapter_optimizer.step()\n                    adapter_optimizer.zero_grad()\n                if adapter_scheduler is not None:\n                    adapter_scheduler.step()\n\n            if glb_step > num_training_steps:\n                leave_training = True\n                break\n\n        val_acc, val_loss = calculate_loss_and_f1(promptModel, validation_data_loader)\n        epoch_traces.append(epoch)\n        acc_traces.append(val_acc)\n        validation_loss_traces.append(val_loss)\n        print(\"Validation: [Epoch: {}, Macro F1: {}, Validation Loss: {}, Time per Epoch: {}]\".format(epoch, val_acc, val_loss, time.time()-epoch_start_time), flush=True)\n\n        if val_acc > best_val_acc:\n            torch.save(promptModel.state_dict(),f\"best_model_{script}.ckpt\")\n            best_val_acc = val_acc\n            best_epoch = epoch\n\n        elif (epoch - best_epoch) >= early_stop_epoch_thresh:\n            print(\"Training stopped early at Epoch: %d\" % epoch)\n            break  # Terminate the training loop\n\n        if leave_training:\n            break\n    \n    promptModel.load_state_dict(torch.load(f\"best_model_{script}.ckpt\"))\n    if use_cuda:\n        promptModel = promptModel.cuda()\n        \n    return promptModel, epoch_traces, acc_traces, validation_loss_traces","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:41:55.946346Z","iopub.execute_input":"2023-05-15T03:41:55.946809Z","iopub.status.idle":"2023-05-15T03:41:55.96464Z","shell.execute_reply.started":"2023-05-15T03:41:55.946762Z","shell.execute_reply":"2023-05-15T03:41:55.963396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train the Models**\n","metadata":{"papermill":{"duration":0.018957,"end_time":"2023-05-07T15:21:00.520668","exception":false,"start_time":"2023-05-07T15:21:00.501711","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"*Latin*","metadata":{}},{"cell_type":"code","source":"promptModel_latin, epoch_traces_latin, acc_traces_latin, validation_loss_traces_latin = train(\n    script = \"latin\", promptModel = promptModel_latin, \n    sp_lr = latin_sp_lr, sv_gp_1_lr = latin_sv_gp_1_lr, sv_gp_2_lr = latin_sv_gp_2_lr, num_warmup_steps = latin_num_warmup_steps,\n    train_data_loader = train_data_loader_latin, validation_data_loader = validation_data_loader_latin\n)","metadata":{"papermill":{"duration":3289.764021,"end_time":"2023-05-07T16:15:54.811899","exception":false,"start_time":"2023-05-07T15:21:05.047878","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:41:55.965921Z","iopub.execute_input":"2023-05-15T03:41:55.966577Z","iopub.status.idle":"2023-05-15T03:47:05.526839Z","shell.execute_reply.started":"2023-05-15T03:41:55.966541Z","shell.execute_reply":"2023-05-15T03:47:05.525412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Sinhala*","metadata":{}},{"cell_type":"code","source":"promptModel_sinhala, epoch_traces_sinhala, acc_traces_sinhala, validation_loss_traces_sinhala = train(\n    script = \"sinhala\", promptModel = promptModel_sinhala, \n    sp_lr = sinhala_sp_lr, sv_gp_1_lr = sinhala_sv_gp_1_lr, sv_gp_2_lr = sinhala_sv_gp_2_lr, num_warmup_steps = sinhala_num_warmup_steps,\n    train_data_loader = train_data_loader_sinhala, validation_data_loader = validation_data_loader_sinhala\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:47:05.528187Z","iopub.status.idle":"2023-05-15T03:47:05.528921Z","shell.execute_reply.started":"2023-05-15T03:47:05.528638Z","shell.execute_reply":"2023-05-15T03:47:05.528672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Mixed*","metadata":{}},{"cell_type":"code","source":"promptModel_mixed, epoch_traces_mixed, acc_traces_mixed, validation_loss_traces_mixed = train(\n    script = \"mixed\", promptModel = promptModel_mixed, \n    sp_lr = mixed_sp_lr, sv_gp_1_lr = mixed_sv_gp_1_lr, sv_gp_2_lr = mixed_sv_gp_2_lr, num_warmup_steps = mixed_num_warmup_steps,\n    train_data_loader = train_data_loader_mixed, validation_data_loader = validation_data_loader_mixed\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:47:05.530264Z","iopub.status.idle":"2023-05-15T03:47:05.53098Z","shell.execute_reply.started":"2023-05-15T03:47:05.530713Z","shell.execute_reply":"2023-05-15T03:47:05.530738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation\n","metadata":{"papermill":{"duration":0.087768,"end_time":"2023-05-07T16:15:54.989641","exception":false,"start_time":"2023-05-07T16:15:54.901873","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Script-Wise Validation**","metadata":{}},{"cell_type":"code","source":"t = PrettyTable()\nt.field_names = ['Script', 'Accuracy', 'Precision', 'Recall', 'F1', 'Macro Precision', 'Macro Recall', 'Macro F1']","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:47:05.532235Z","iopub.status.idle":"2023-05-15T03:47:05.532954Z","shell.execute_reply.started":"2023-05-15T03:47:05.532686Z","shell.execute_reply":"2023-05-15T03:47:05.53271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Latin*","metadata":{}},{"cell_type":"code","source":"val_preds_latin, val_labels_latin = predict(promptModel_latin, validation_data_loader_latin)\nres = compute_metrics(val_preds_latin, val_labels_latin)\nt.add_row([\"Latin\", res['accuracy'], res['precision'], res['recall'], res['f1'], res['macro_precision'], res['macro_recall'], res['macro_f1']])","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:47:05.534213Z","iopub.status.idle":"2023-05-15T03:47:05.534935Z","shell.execute_reply.started":"2023-05-15T03:47:05.534639Z","shell.execute_reply":"2023-05-15T03:47:05.534678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" *Sinhala*","metadata":{}},{"cell_type":"code","source":"val_preds_sinhala, val_labels_sinhala = predict(promptModel_sinhala, validation_data_loader_sinhala)\nres = compute_metrics(val_preds_sinhala, val_labels_sinhala)\nt.add_row([\"Sinhala\", res['accuracy'], res['precision'], res['recall'], res['f1'], res['macro_precision'], res['macro_recall'], res['macro_f1']])","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:47:05.536176Z","iopub.status.idle":"2023-05-15T03:47:05.536883Z","shell.execute_reply.started":"2023-05-15T03:47:05.536607Z","shell.execute_reply":"2023-05-15T03:47:05.536631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Mixed*","metadata":{}},{"cell_type":"code","source":"val_preds_mixed, val_labels_mixed = predict(promptModel_mixed, validation_data_loader_mixed)\nres = compute_metrics(val_preds_mixed, val_labels_mixed)\nt.add_row([\"Mixed\", res['accuracy'], res['precision'], res['recall'], res['f1'], res['macro_precision'], res['macro_recall'], res['macro_f1']], divider=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:47:05.538116Z","iopub.status.idle":"2023-05-15T03:47:05.538822Z","shell.execute_reply.started":"2023-05-15T03:47:05.538546Z","shell.execute_reply":"2023-05-15T03:47:05.538569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Overall Validation**","metadata":{}},{"cell_type":"code","source":"val_preds, val_labels = (val_preds_latin+val_preds_sinhala+val_preds_mixed), (val_labels_latin+val_labels_sinhala+val_labels_mixed)\nres = compute_metrics(val_preds, val_labels)\nt.add_row([\"Overall\", res['accuracy'], res['precision'], res['recall'], res['f1'], res['macro_precision'], res['macro_recall'], res['macro_f1']])","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:47:05.540057Z","iopub.status.idle":"2023-05-15T03:47:05.54077Z","shell.execute_reply.started":"2023-05-15T03:47:05.540511Z","shell.execute_reply":"2023-05-15T03:47:05.540534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Plot Validation Graphs*","metadata":{}},{"cell_type":"code","source":"def plot_validation_graphs(script, epoch_traces, acc_traces, validation_loss_traces):\n    plt.figure(figsize=(20,5))\n    \n    plt.subplot(1, 2, 1) # row 1, col 2 index 1\n    plt.plot(range(len(epoch_traces)), acc_traces)\n    plt.xlabel('Epoch')\n    plt.ylabel('Macro F1-Score')\n    plt.title(script + ' : Epoch vs Validation Macro F1-Score')\n    plt.xticks(range(len(epoch_traces)), epoch_traces)\n    \n    plt.subplot(1, 2, 2) # index 2\n    plt.plot(range(len(epoch_traces)), validation_loss_traces)\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title(script + ' : Epoch vs Validation Loss')\n    plt.xticks(range(len(epoch_traces)), epoch_traces)\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:47:05.542053Z","iopub.status.idle":"2023-05-15T03:47:05.542734Z","shell.execute_reply.started":"2023-05-15T03:47:05.542481Z","shell.execute_reply":"2023-05-15T03:47:05.542503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(t.get_string(fields=[\"Script\", \"Accuracy\", \"Macro F1\"]))\nplot_validation_graphs(\"Latin\", epoch_traces_latin, acc_traces_latin, validation_loss_traces_latin)\nplot_validation_graphs(\"Sinhala\", epoch_traces_sinhala, acc_traces_sinhala, validation_loss_traces_sinhala)\nplot_validation_graphs(\"Mixed\", epoch_traces_mixed, acc_traces_mixed, validation_loss_traces_mixed)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:47:05.544019Z","iopub.status.idle":"2023-05-15T03:47:05.54483Z","shell.execute_reply.started":"2023-05-15T03:47:05.544452Z","shell.execute_reply":"2023-05-15T03:47:05.544474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test\n","metadata":{"papermill":{"duration":0.087759,"end_time":"2023-05-07T16:16:15.919855","exception":false,"start_time":"2023-05-07T16:16:15.832096","status":"completed"},"tags":[]}},{"cell_type":"code","source":"t = PrettyTable()\nt.field_names = ['Script', 'Accuracy', 'Precision', 'Recall', 'F1', 'Ma. Precision', 'Ma. Recall', 'Ma. F1']","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:47:05.553368Z","iopub.status.idle":"2023-05-15T03:47:05.553948Z","shell.execute_reply.started":"2023-05-15T03:47:05.553734Z","shell.execute_reply":"2023-05-15T03:47:05.553753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Script-Wise Evaluation**\n","metadata":{"papermill":{"duration":0.090363,"end_time":"2023-05-07T16:16:33.58102","exception":false,"start_time":"2023-05-07T16:16:33.490657","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"_Latin Script_\n","metadata":{"papermill":{"duration":0.088029,"end_time":"2023-05-07T16:16:33.758927","exception":false,"start_time":"2023-05-07T16:16:33.670898","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_preds_latin, test_labels_latin = predict(promptModel_latin, test_data_loader_latin)\nres = compute_metrics(test_preds_latin, test_labels_latin)\nres = {key : round(res[key], 4) for key in res}\nt.add_row([\"Latin\", res['accuracy'], res['precision'], res['recall'], res['f1'], res['macro_precision'], res['macro_recall'], res['macro_f1']])","metadata":{"papermill":{"duration":13.315237,"end_time":"2023-05-07T16:16:47.163242","exception":false,"start_time":"2023-05-07T16:16:33.848005","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:47:05.554927Z","iopub.status.idle":"2023-05-15T03:47:05.555885Z","shell.execute_reply.started":"2023-05-15T03:47:05.555588Z","shell.execute_reply":"2023-05-15T03:47:05.555612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_Sinhala Script_\n","metadata":{"papermill":{"duration":0.089126,"end_time":"2023-05-07T16:16:47.342898","exception":false,"start_time":"2023-05-07T16:16:47.253772","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_preds_sinhala, test_labels_sinhala = predict(promptModel_sinhala, test_data_loader_sinhala)\nres = compute_metrics(test_preds_sinhala, test_labels_sinhala)\nres = {key : round(res[key], 4) for key in res}\nt.add_row([\"Sinhala\", res['accuracy'], res['precision'], res['recall'], res['f1'], res['macro_precision'], res['macro_recall'], res['macro_f1']])","metadata":{"papermill":{"duration":5.45372,"end_time":"2023-05-07T16:16:52.886218","exception":false,"start_time":"2023-05-07T16:16:47.432498","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:47:05.557134Z","iopub.status.idle":"2023-05-15T03:47:05.557886Z","shell.execute_reply.started":"2023-05-15T03:47:05.557612Z","shell.execute_reply":"2023-05-15T03:47:05.557636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_Mixed Script_\n","metadata":{"papermill":{"duration":0.090692,"end_time":"2023-05-07T16:16:53.067028","exception":false,"start_time":"2023-05-07T16:16:52.976336","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_preds_mixed, test_labels_mixed = predict(promptModel_mixed, test_data_loader_mixed)\nres = compute_metrics(test_preds_mixed, test_labels_mixed)\nres = {key : round(res[key], 4) for key in res}\nt.add_row([\"Mixed\", res['accuracy'], res['precision'], res['recall'], res['f1'], res['macro_precision'], res['macro_recall'], res['macro_f1']], divider=True)","metadata":{"papermill":{"duration":5.560854,"end_time":"2023-05-07T16:16:58.717848","exception":false,"start_time":"2023-05-07T16:16:53.156994","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T03:47:05.55913Z","iopub.status.idle":"2023-05-15T03:47:05.55987Z","shell.execute_reply.started":"2023-05-15T03:47:05.559564Z","shell.execute_reply":"2023-05-15T03:47:05.559588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Overall Evaluation**","metadata":{}},{"cell_type":"code","source":"test_preds, test_labels = (test_preds_latin+test_preds_sinhala+test_preds_mixed), (test_labels_latin+test_labels_sinhala+test_labels_mixed)\nres = compute_metrics(test_preds, test_labels)\nres = {key : round(res[key], 4) for key in res}\nt.add_row([\"Overall\", res['accuracy'], res['precision'], res['recall'], res['f1'], res['macro_precision'], res['macro_recall'], res['macro_f1']])","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:47:05.561129Z","iopub.status.idle":"2023-05-15T03:47:05.561843Z","shell.execute_reply.started":"2023-05-15T03:47:05.561565Z","shell.execute_reply":"2023-05-15T03:47:05.561589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(t)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:47:05.563073Z","iopub.status.idle":"2023-05-15T03:47:05.56377Z","shell.execute_reply.started":"2023-05-15T03:47:05.56351Z","shell.execute_reply":"2023-05-15T03:47:05.563534Z"},"trusted":true},"execution_count":null,"outputs":[]}]}